\documentclass[a4paper,14pt]{article}

% Packages
\usepackage{graphicx}  % For images
\usepackage{amsmath}   % For math symbols
\usepackage{hyperref}  % For hyperlinks
\usepackage{fancyhdr}  % For headers
\usepackage{geometry}  % For page layout
\usepackage{xcolor}   % For colors
\usepackage{listings} % For code snippets
\usepackage{float}     % For image positioning
% \usepackage[format=plain,justification=center]{caption}
\usepackage[utf8]{inputenc} % For special characters
\geometry{a4paper, margin=1in}
\usepackage{pgfplots}
\usepackage{tikz}
\pgfplotsset{compat=1.18}

% Fancy header/footer settings
\pagestyle{fancy}
\fancyfoot[R]{\thepage} % Right-align page number in the footer

\pagestyle{fancy}
\fancyfoot[R]{\thepage} % Right-align page number in the footer


% Title information
\title{Lab Report: Text, Audio, and Image Data Manipulation}
\author{107474-Joseane Pereira \\
109050-Gabriel Costa \\
108538-Francisco Gon√ßalves \\
Universidade de Aveiro, DETI}
\date{\today}


\begin{document}
\begin{figure}
    \centering
    \includegraphics[width=0.3\linewidth]{ua.pdf}
    \label{fig:enter-label}
\end{figure}
\maketitle
\newpage
\tableofcontents
\newpage

\section{Introduction}
This project implements a video codec system using both intra-frame and inter-frame compression techniques. The implementation focuses on efficient compression while maintaining video quality through predictive coding, motion estimation, and Golomb encoding.

\section{System Architecture}

\subsection{Core Components}
The system consists of four main components:
\begin{itemize}
    \item \textbf{BitStream}: Handles bit-level I/O operations for binary file manipulation
    \item \textbf{Golomb Codec}: Implements Golomb-Rice coding for entropy encoding
    \item \textbf{Audio Codec}: Audio compression using predictive and inter-channel coding
    \item \textbf{Image Codec}: Manages image compression using predictive coding
    \item \textbf{Video Codecs}: Implements both intra-frame and inter-frame compression
\end{itemize}

\subsection{Implementation Details}

\subsubsection{BitStream Class}
Provides low-level bit manipulation:
\begin{itemize}
    \item Bit-level read/write operations
    \item Buffer management for efficient I/O
    \item Support for variable-length integer encoding
\end{itemize}

\subsubsection{Golomb Encoding}
Implements efficient entropy coding:
\begin{itemize}
    \item Parameter 'm' optimization for data characteristics
    \item Support for both signed and unsigned integers
    \item Zigzag encoding for efficient signed number representation
\end{itemize}

\section{Audio Codec}
In audio coding, our objective was to explore various audio compression methods aimed at reducing file size while preserving audio quality. To achieve this, we implemented two key approaches: a polynomial-based algorithm and an inter-channel residual calculation algorithm for lossless compression. For lossy compression, the polynomial algorithm was adapted by incorporating a quantization step.

\subsection{Results}
% \subsection{Performance Metrics}
We tested two different samples with the algorithms:
\begin{itemize}
    \item \textbf{Predictive coding (order 3)}: Uses the last 3 samples of the same channel
    \item \textbf{Inter-channel}: Uses the left channel to predict the samples of the right channel
    \item \textbf{Predictive coding lossy}: Uses the first method, quantizing the residuals    
\end{itemize}

We evaluated the compression based on:
    \begin{itemize}
        \item The size of the compressed file generated
        \item Execution/Computation time (encoder + decoder)
        \item The "Signal-to-Noise Ratio"
    \end{itemize}


For the sample "sample02.wav" we obtained the following results, where in lossy coding, we had 8 bitrate:

% FINISH THIS
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Original Size} & \textbf{Compressed Size} & \textbf{Compression Ratio} & \textbf{Exec Time} & \textbf{SNR}\\
\hline
Polynomial & 2.5 MB & 2.30 MB & 8.0\% & 132 + 211 ms & inf\\
Inter-Channel & 2.5 MB & 2.29 MB & 8.4\% & 111 + 180 ms & inf\\
Lossy & 2.5 MB & 1.01 MB & 59.6\% & 72 + 144 ms & 24.9 dB\\
\hline
\end{tabular}
\caption{Compression Performance Comparison}
\end{table}

For the sample "sample01.wav" (the biggest sample), we obtained the following results, where in lossy coding, we had 8 bitrate:
% FINISH THIS
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Original Size} & \textbf{Compressed Size} & \textbf{Compression Ratio} & \textbf{Exec Time} & \textbf{SNR}\\
\hline
Polynomial & 5.2 MB & 4.27 MB & 17.9\% & 224 + 422 ms & inf\\ 
Inter-Channel & 5.2 MB & 4.41 MB & 15.2\% & 227 + 362 ms & inf\\
Lossy & 5.2 MB & 1.69 MB & 67.5\% & 137 + 270 ms & 28.5 dB\\
\hline
\end{tabular}
\caption{Compression Performance Comparison}
\end{table}



As we can see, there is no noticeable compression difference between inter-channel coding and predictive coding in the lossless category, and since we obtained infinite SNR for the lossless codecs, it means that it generated no noise (as it should). 

On the other hand, the lossy codec has a noticeable difference in compression size while also reducing the computation time. The problem is based on the noise generated. The SNR value reveals that there is in fact some noise, but it is not too noticeable, even after using 8 bitrate (half of the original). 
% As we can see, the lossy audio codec can achieve much higher compression rates without compromising too much the audio quality.

% NAO SEI COMO COMPARAR COM O MP3
\subsection{Comparative Analysis}
Our lossy encoder achieves at best, a 68\% size reduction from the original WAV file without too noticeable audio differences. In contrast, industry-standard codecs like MP3 typically achieve around a 75\% reduction while preserving good audio quality. This difference highlights the efficiency difference between our implementation and well-established, optimized codecs. 

The primary factor driving this difference is the use of advanced techniques in industry-level codecs, such as psychoacoustic models. These models exploit human auditory perception to discard inaudible data, allowing for much higher compression ratios without perceptible quality loss. Integrating such sophisticated approaches is crucial for achieving competitive performance in audio compression.



\subsection{Limitations and Improvements}
Our prediction model currently supports fixed-order linear predictors but lacks adaptive or non-linear capabilities, limiting its effectiveness in modeling complex audio signals. Additionally, the predictor assumes consistent channel separation and strictly linear patterns, which are not guaranteed for all audio inputs.

Golomb coding, while efficient for certain residuals, performs poorly with high-entropy data. Alternative methods like Huffman or arithmetic coding could yield better compression results.

Moreover, the encoded file is vulnerable to error propagation, where a single error can distort the entire signal, significantly degrading sound quality.


\section{Image Codec}
The image codec implements multiple prediction modes to achieve optimal compression:

\begin{itemize}
    \item \textbf{Spatial Predictors}:
    \begin{itemize}
        \item \textbf{Predictor A (West)}: Uses the pixel to the left, optimal for horizontal gradients
        \item \textbf{Predictor B (North)}: Uses the pixel above, best for vertical patterns
        \item \textbf{Predictor C (Northwest)}: Uses the diagonal pixel, effective for diagonal textures
        \item \textbf{JPEG-LS}: Adaptive predictor that combines A, B, and C based on local gradients:
        \begin{equation}
            P(x,y) = \begin{cases}
                min(A,B) & \text{if } C \geq max(A,B) \\
                max(A,B) & \text{if } C \leq min(A,B) \\
                A + B - C & \text{otherwise}
            \end{cases}
        \end{equation}
    \end{itemize}

  
\end{itemize}



where $a$, $b$, and $c$ are the West, North, and Northwest pixels respectively.

\subsection{Golomb Parameter Optimization}
The optimal Golomb parameter $m$ is estimated using the mean absolute value of residuals:

\textbf{Golomb Parameter Optimization}:
    \begin{itemize}
        \item Dynamic m calculation based on residual statistics
        \item Uses mean absolute value ($\mu$) of residuals:
        \begin{equation}
            m = \left\lceil -\frac{1}{\log_2(\frac{\mu}{\mu+1})} \right\rceil
        \end{equation}
        \item Adapts to local image characteristics
        \item Optimized separately for each color channel
    \end{itemize}


where $\mu$ is the mean absolute residual value. This approach minimizes the expected code length based on the geometric distribution of residuals.

\subsection{Results}
We conducted extensive testing using standard test images, including the Lena image (786,447 bytes). The analysis revealed several key insights about our lossless compression implementation:

\begin{figure}[!htb]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{lena.png}
        \caption{Original Lena Test Image}
        \label{fig:lena_original}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=\textwidth,
                xlabel={Golomb Parameter (m)},
                ylabel={Compression Ratio},
                grid=major,
                title={Compression Performance},
                ymin=0.5, ymax=0.8,
                xmin=2, xmax=8,
                xtick={2,3,4,5,6,7,8},
                legend style={
                    at={(0.5,-0.2)},  % Position below the plot
                    anchor=north,      % Anchor at the top
                    legend columns=3,  % Spread legend entries horizontally
                    cells={anchor=west},
                    draw=none         % No border around legend
                }
            ]
            % Red channel performance
            \addplot[red,mark=*] coordinates {
                (4,0.72)
                (5,0.72)
                (6,0.72)
                (7,0.73)
            };
            % Green channel performance
            \addplot[green,mark=square] coordinates {
                (4,0.74)
                (5,0.74)
                (6,0.74)
                (7,0.74)
            };
            % Blue channel performance
            \addplot[blue,mark=triangle] coordinates {
                (4,0.59)
                (5,0.60)
                (6,0.73)
                (7,0.74)
            };
            \legend{Red Channel, Green Channel, Blue Channel}
            \end{axis}
        \end{tikzpicture}
        \caption{Channel-specific Compression Ratio vs. Golomb Parameter}
        \label{fig:compression_ratio}
    \end{minipage}
\end{figure}

\begin{table}[!htb]
\centering
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Predictor} & \textbf{Channel} & \textbf{Comp.Ratio} & \textbf{Time(ms)} & \textbf{Opt. m} \\
\hline
JPEG-LS & R & 72\% & 23 & 6 \\
JPEG-LS & G & 72\% & 22 & 5 \\
JPEG-LS & B & 59\% & 21 & 4 \\
\hline
North & R & 72\% & 17 & 6 \\
North & G & 74\% & 16 & 5 \\
North & B & 60\% & 16 & 4 \\
\hline
Northwest & R & 73\% & 17 & 7 \\
Northwest & G & 74\% & 18 & 7 \\
Northwest & B & 74\% & 16 & 6 \\
\hline
West & R & 72\% & 25 & 7 \\
West & G & 74\% & 17 & 6 \\
West & B & 73\% & 16 & 5 \\
\hline
\end{tabular}
\caption{Detailed Predictor Performance Analysis for Lena Image}
\label{tab:detailed_predictor_comparison}
\end{table}

\paragraph{}
Key observations from the experimental results:
\begin{itemize}
    \item \textbf{Overall Compression}: The initial implementation achieved a 1:1 compression ratio with 0\% bit error rate, indicating perfect lossless reconstruction
    
    \item \textbf{Channel-Specific Performance}:
    \begin{itemize}
        \item Best compression achieved by JPEG-LS on blue channel (0.59 ratio)
        \item Green channel showed consistent compression (0.72-0.74) across all predictors
        \item Red channel performance varied between 0.72-0.73
    \end{itemize}
    
    \item \textbf{Processing Efficiency}:
    \begin{itemize}
        \item North predictor fastest overall (16-17ms)
        \item JPEG-LS slightly slower (21-23ms) but better compression
        \item West predictor slowest for red channel (25ms)
    \end{itemize}
    
    \item \textbf{Optimal m Values}:
    \begin{itemize}
        \item Range: 4-7 across all predictors and channels
        \item Blue channel consistently uses lower m values (4-6)
        \item Northwest predictor requires higher m values (6-7)
    \end{itemize}
\end{itemize}

\section{Video Compression Techniques}

\subsection{Intra-Frame Coding}
The \texttt{IntraFrameVideoCodec} in C++ provides frame-independent compression with optimized spatial prediction and efficient entropy coding:

\begin{itemize}
\item \textbf{Optimized Prediction Model}: Enhanced horizontal pixel prediction across Y, U, and V planes using OpenCV operations for reduced residuals.
\item \textbf{Dynamic Format Handling}: Native support for YUV420p with real-time conversion from YUV422 and YUV444 formats.
\item \textbf{Golomb Coding Efficiency}: Residuals encoded via Golomb coding, enhanced by a user-defined \texttt{m} parameter.
\item \textbf{Y4M Format Parsing}: Robust parsing of Y4M headers for adaptive video dimension and format handling.
\item \textbf{Progress Tracking}: Real-time encoding and decoding progress updates for user feedback.
\end{itemize}

\subsubsection{Comparative Analysis}
\begin{itemize}
\item \textbf{Versus JPEG/H.264}: Provides purely lossless compression, unlike JPEG or H.264, making it suitable for high-fidelity use cases.
\item \textbf{Compression Efficiency}: Lower than H.264 due to the absence of inter-frame prediction and transform coding.
\end{itemize}

\subsubsection{Challenges}
\begin{itemize}
\item \textbf{Dimension Validation}: Strict enforcement of even dimensions for YUV420p compatibility.
\item \textbf{Adaptive Format Parsing}: Handling diverse YUV formats.
\end{itemize}

\subsection{Inter-Frame Coding}
The \texttt{InterFrameVideoCodec} in C++ implements efficient video compression through predictive coding, supporting both intra-frame (I-frame) and inter-frame (P-frame) encoding.

\begin{itemize}
\item \textbf{Prediction Models}: Combines spatial intra-frame prediction with motion-compensated inter-frame prediction.
\item \textbf{Block-Based Encoding}: Processes video frames in blocks with adjustable sizes and incorporates adaptive search ranges for efficiency.
\item \textbf{Motion Estimation and Compensation}: Employs constrained search ranges and Sum of Absolute Differences (SAD) for motion vector accuracy.
\item \textbf{Residual Management}: Encodes and quantizes residuals from predictions to optimize data storage.
\item \textbf{Differential Motion Vector Encoding}: Reduces redundancy by encoding motion vector differences using Golomb coding.
\end{itemize}

\subsubsection{Temporal Prediction}
\begin{itemize}
\item \textbf{Hierarchical Motion Estimation}: Combines multi-scale search with constrained boundaries to ensure accuracy and computational efficiency.
\item \textbf{Skip Mode}: Skips blocks with residuals below a defined threshold to further minimize data storage.
\item \textbf{Rate-Distortion Optimization}: Dynamically selects between intra-frame and inter-frame coding modes based on residual and motion vector costs.
\end{itemize}

\subsubsection{Comparative Analysis}
\begin{itemize}
\item \textbf{Golomb Coding Efficiency}: Applies Golomb encoding for motion vectors and residuals, reducing storage costs with run-length optimizations.
\item \textbf{Versus H.264}: Simpler than H.264, focusing on basic motion estimation, single reference frames, and no sub-pixel precision, yet efficient due to adaptive quantization and constrained encoding strategies.
\end{itemize}

\subsubsection{Challenges}
\begin{itemize}
\item \textbf{Motion Estimation Complexity}: Balancing accuracy with computational overhead, particularly during hierarchical searches.
\item \textbf{Error Propagation}: Addressing cumulative errors introduced by quantization in inter-frame predictions.
\item \textbf{Memory Management}: Efficiently handling large video frames and buffers, especially during encoding/decoding.
\end{itemize}

\subsubsection{Identified Limitations}
\begin{itemize}
\item \textbf{Motion Estimation Simplifications}: Lacks sub-pixel precision, multiple reference frames, and advanced search patterns like diamond or hexagon searches.
\item \textbf{Skip Mode Thresholding}: Fixed thresholds might not adapt optimally to varying content across videos.
\end{itemize}

\subsection{Lossy Inter-Frame Coding}
The \texttt{InterFrameVideoLossyCodec} enhances the base codec with advanced lossy compression techniques:

\begin{itemize}
\item \textbf{Dead-Zone Quantization}: Suppresses insignificant data using quantization with configurable steps for higher compression.
\item \textbf{Adaptive Quantization Control}: Dynamically adjusts quantization levels based on scene complexity.
\item \textbf{Run-Length Encoding}: Efficiently encodes zero residual runs to reduce entropy coding overhead.
\item \textbf{Golomb Coding Integration}: Integrates optimized Golomb coding with zero-run length encoding.
\item \textbf{Chroma Subsampling Optimization}: Applies higher quantization to chroma components for perceptual quality retention.
\end{itemize}

\subsubsection{Comparative Analysis}
\begin{itemize}
\item \textbf{Versus H.264}: Simpler but achieves effective compression through adaptive quantization and motion estimation.
\item \textbf{Golomb Coding Efficiency}: Enhanced with zero-run and run-length optimizations.
\item \textbf{Lossy Compression Gains}: Achieves higher compression ratios with controlled quality loss.
\end{itemize}

\subsubsection{Challenges}
\begin{itemize}
\item \textbf{Motion Estimation Complexity}: Balancing computational cost with motion accuracy.
\item \textbf{Error Propagation}: Controlling error accumulation due to quantization.
\item \textbf{Quantization Trade-offs}: Managing the balance between compression efficiency and visual quality.
\end{itemize}

\subsubsection{Identified Limitations}
\begin{itemize}
\item \textbf{Fixed Quantization Levels}: Limited adaptability across diverse content types.
\item \textbf{Lack of Transform Coding}: Absence of DCT or wavelet transforms reduces compression efficiency.
\item \textbf{Basic Motion Estimation}: Lacks sub-pixel precision and multi-reference frames.
\end{itemize}


\section{Conclusion}
This project successfully implemented a comprehensive multimedia compression system, demonstrating effective techniques across three key domains:

\subsection{Audio Compression}
Our audio codec achieved significant results:
\begin{itemize}
    \item Lossless compression with predictive coding reached 15-18\% size reduction
    \item Inter-channel coding showed similar efficiency (15-17\% reduction)
    \item Lossy implementation achieved up to 68\% size reduction while maintaining good audio quality
    \item Processing times remained efficient (under 500ms for 5MB files)
\end{itemize}

\subsection{Image Compression}
The image codec demonstrated strong performance:
\begin{itemize}
    \item Perfect reconstruction in lossless mode with compression ratios of 0.59-0.74
    \item JPEG-LS predictor showed superior performance, especially for blue channel (0.59 ratio)
    \item Dynamic Golomb parameter optimization (m=4-7) improved efficiency
    \item Fast processing times (16-25ms per channel)
\end{itemize}

\subsection{Video Compression}
Video compression implementation revealed:
\begin{itemize}
    \item Effective intra-frame coding using spatial redundancy
    \item Inter-frame compression with motion estimation reduced file sizes
    \item Block-based processing with configurable parameters
    \item Successful integration of image codec techniques for frame compression
\end{itemize}

\subsection{Technical Achievements}
Key innovations across all implementations include:
\begin{itemize}
    \item Efficient bit-level I/O operations
    \item Adaptive parameter selection for optimal compression
    \item Modular design allowing component reuse
    \item Balance between compression efficiency and processing speed
\end{itemize}

\subsection{Future Directions}
While the current implementation meets its core objectives, several opportunities for enhancement exist:
\begin{itemize}
    \item Implementation of B-frames for video compression
    \item Parallel processing for improved performance
    \item More sophisticated audio prediction models
    \item Advanced rate control mechanisms
\end{itemize}

In conclusion, this project successfully demonstrated the implementation of fundamental compression techniques while maintaining modularity and efficiency. The results show competitive performance compared to standard formats, particularly in lossless compression scenarios, while providing insights into the tradeoffs between compression ratio, quality, and computational complexity.

\end{document}



